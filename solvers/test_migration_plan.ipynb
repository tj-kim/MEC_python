{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Migration Plan\n",
    "\n",
    "Test Migration plan class (in classes folder) by:\n",
    "- First make ILP problem identical to last time\n",
    "- Make mig class based on users created\n",
    "- Try to devise a way to take ILP decision values and make plan out of that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Generic Classes\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "# Import All Custom Classes\n",
    "import os, sys\n",
    "sys.path.append(os.path.pardir+\"/classes\")\n",
    "\n",
    "from Server import *\n",
    "from User import *\n",
    "from Link import *\n",
    "from Job import *\n",
    "\n",
    "# Import Solver Classes\n",
    "from Optim_PlanGenerator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class Migration_Plans:\n",
    "    \"\"\"\n",
    "    Migration_Plans: \n",
    "        - Collects all migration plans generated for an entire system\n",
    "        - mig_plan_dict : 6 x time_steps np array with rows\n",
    "            - timeslot, user_active_flag, usr_voronoi, source_svr, dest_svr, mig_rate\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, users, jobs, sim_params):\n",
    "        \"\"\"\n",
    "        users - list of user class (used to extract user location)\n",
    "        time_steps - how many timesteps to simulate user movement for\n",
    "        \"\"\"\n",
    "        \n",
    "        self.mig_plan_dict = {}\n",
    "        self.sim_params = sim_params\n",
    "        \n",
    "        # Initialize dictionary \n",
    "        self.dict_init(users,jobs,sim_params.time_steps)\n",
    "    \n",
    "    \"\"\"\n",
    "    Init Helper Function\n",
    "    \"\"\"\n",
    "    \n",
    "    def dict_init(self, users, jobs, time_steps):\n",
    "        \n",
    "        param_collection = [\"time_slot\", \"user_active_flag\", \n",
    "                            \"user_voronoi\", \"source_server\", \n",
    "                            \"dest_server\", \"mig_rate\",\n",
    "                            \"mig_link_id\", \"service_link_id\",\n",
    "                            \"service_thruput\", \"latency\"]\n",
    "        \n",
    "        for u in range(len(users)):\n",
    "            temp_usr_dict = {}\n",
    "            \n",
    "            for p in param_collection:\n",
    "                temp_usr_dict[p] = np.zeros(time_steps)\n",
    "            \n",
    "            # Record active time and user voronoi\n",
    "            for t in range(int(time_steps)):\n",
    "                temp_usr_dict[\"time_slot\"][t] = t\n",
    "                temp_usr_dict[\"user_voronoi\"][t] = users[u].user_voronoi_true[t]\n",
    "                temp_usr_dict[\"user_active_flag\"][t] = jobs[u].active_time[t]\n",
    "            \n",
    "            self.mig_plan_dict[u] = temp_usr_dict\n",
    "    \n",
    "    \"\"\"\n",
    "    Extraction Functions\n",
    "    \"\"\"\n",
    "    \n",
    "    def from_ILP(self, ILP_prob):\n",
    "        \"\"\"\n",
    "        From decision variables h we want to replace the zero vectors of \n",
    "        self.mig_plan_dict with relevant values based on the decision vars\n",
    "        \n",
    "        Input: ILP_prob - an Optim_PlanGenerator object that already has been optimized\n",
    "        \"\"\"\n",
    "        \n",
    "        # 1. Loop through all h_vars and obtain those that have been selected\n",
    "        h_hit_keys = []\n",
    "        \n",
    "        for h_key in ILP_prob.h_vars.keys():\n",
    "            if ILP_prob.h_vars[h_key].varValue>0:\n",
    "                h_hit_keys += [h_key]\n",
    "            \n",
    "        \n",
    "        # 2. Loop through each of the users and isolate variables that pertain to them\n",
    "        for j in range(len(ILP_prob.jobs)):\n",
    "            uh_keys = []\n",
    "            \n",
    "            # Collect all keys from a certain user\n",
    "            for hit_key in h_hit_keys:\n",
    "                if hit_key[0] == j: # If of the correct user\n",
    "                    uh_keys += [hit_key]\n",
    "            \n",
    "            \n",
    "            # Reorder the hit keys in terms of time\n",
    "            uh_keys_ordered = []\n",
    "            curr_time = -1 \n",
    "            for l in range(len(uh_keys)):\n",
    "                time_key = None\n",
    "                for key in uh_keys:\n",
    "                    if key[3] == curr_time:\n",
    "                        break\n",
    "                uh_keys_ordered += [key]\n",
    "                curr_time = key[4]\n",
    "                uh_keys.remove(key)\n",
    "        \n",
    "            self.ILP_plan_extract(uh_keys_ordered,j)\n",
    "                    \n",
    "        \n",
    "        return\n",
    "    \n",
    "    def from_seq_greedy(self,SG_prob):\n",
    "        \"\"\"\n",
    "        From the migration plan problem, do the entire procedure of reserving resources and \n",
    "        generating final migration plan -- how will we do this for batch?\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "    \n",
    "    \"\"\"\n",
    "    Extraction function helpers\n",
    "    \"\"\"\n",
    "    \n",
    "    # ILP\n",
    "    \n",
    "    def ILP_plan_extract(self, uh_keys_ordered, job_num):\n",
    "        \"\"\"\n",
    "        Loop through the ordered selected keys for a single user \n",
    "        And generate np arrays that will correspond to plans\n",
    "        Inputs:\n",
    "            uh_keys_ordered: list of tupels that represent h-variables in ILP Solution\n",
    "            job_num: job id \n",
    "        \"\"\"\n",
    "        \n",
    "        active = True\n",
    "        inactive = False\n",
    "        \n",
    "        # Loop through each of the keys (Use switch cases below)\n",
    "        for uh_key in uh_keys_ordered:\n",
    "            start_time, end_time = uh_key[3], uh_key[4]\n",
    "            source_server,dest_server = uh_key[1], uh_key[2]\n",
    "            link_path = uh_key[5]\n",
    "            \n",
    "            case = (source_server >= 0, dest_server >= 0) # server source, dest active/inactive\n",
    "            \n",
    "            if case == (active, active) or case == (inactive,inactive):\n",
    "                self.mig_plan_dict[job_num][\"source_server\"][start_time:end_time] = source_server\n",
    "                self.mig_plan_dict[job_num][\"dest_server\"][start_time:end_time] = dest_server\n",
    "                \n",
    "                # Migration length find\n",
    "                if source_server != dest_server:\n",
    "                    mig_length = end_time - start_time\n",
    "                    self.mig_plan_dict[job_num][\"mig_rate\"][start_time:end_time] = 1/mig_length\n",
    "                    self.mig_plan_dict[job_num][\"mig_link_id\"][start_time:end_time] = link_path\n",
    "                    \n",
    "            elif case == (inactive, active) or case == (active, inactive):\n",
    "                # The entire column in the plan is considered inactive/active\n",
    "                self.mig_plan_dict[job_num][\"source_server\"][start_time:end_time] = source_server\n",
    "                self.mig_plan_dict[job_num][\"dest_server\"][start_time:end_time] = source_server\n",
    "    \n",
    "    # HEuristic\n",
    "    \n",
    "    def seq_greedy_plan_extract(self, node_orders, link_path_orders, job_num):\n",
    "        \"\"\"\n",
    "        Loop through the ordered selected nodes for a single user \n",
    "        And generate np arrays that will correspond to plans\n",
    "        Inputs:\n",
    "            node_orders: Sequence of nodes in mig graph that make up a plan\n",
    "            link_path_orders : which path was taken between two nodes in mig graph\n",
    "            job_num: job id \n",
    "        \"\"\"\n",
    "        \n",
    "        active = True\n",
    "        inactive = False\n",
    "        \n",
    "        # Pull pairs of nodes that are connected together\n",
    "        pair_list = []\n",
    "        path_idx = 0\n",
    "        for i in range(len(node_orders)-1):\n",
    "            pair_list += [(node_orders[i],node_orders[i+1])]\n",
    "        \n",
    "        # Loop through each of the keys (Use switch cases below)\n",
    "        for (node1,node2) in pair_list:\n",
    "            (source_server, start_time) = self.convert_node2st[j][node1]\n",
    "            (dest_server, end_time) = self.convert_node2st[j][node2]\n",
    "            link_path = link_path_orders[path_idx]\n",
    "            path_idx += 1\n",
    "            \n",
    "            case = (source_server >= 0, dest_server >= 0) # server source, dest active/inactive\n",
    "            \n",
    "            if case == (active, active) or case == (inactive,inactive):\n",
    "                self.mig_plan_dict[job_num][\"source_server\"][start_time:end_time] = source_server\n",
    "                self.mig_plan_dict[job_num][\"dest_server\"][start_time:end_time] = dest_server\n",
    "                \n",
    "                # Migration length find\n",
    "                if source_server != dest_server:\n",
    "                    mig_length = end_time - start_time\n",
    "                    self.mig_plan_dict[job_num][\"mig_rate\"][start_time:end_time] = 1/mig_length\n",
    "                    self.mig_plan_dict[job_num][\"mig_link_id\"][start_time:end_time] = link_path\n",
    "                    \n",
    "            elif case == (inactive, active) or case == (active, inactive):\n",
    "                # The entire column in the plan is considered inactive/active\n",
    "                self.mig_plan_dict[job_num][\"source_server\"][start_time:end_time] = source_server\n",
    "                self.mig_plan_dict[job_num][\"dest_server\"][start_time:end_time] = source_server\n",
    "    \n",
    "    # General\n",
    "        \n",
    "    def reserve_service_bw(self,links,jobs):\n",
    "        \"\"\"\n",
    "        take into a consideration the resources at each link at each timestep, and determine\n",
    "        Inputs:\n",
    "        links - a link instance of the simulation\n",
    "        jobs - a list of job objects each with their job size \n",
    "        \n",
    "        Updates migration plan to determine throughput of service at each instance\n",
    "        \"\"\"\n",
    "        \n",
    "        # Loop through each ts\n",
    "        \n",
    "        # Loop through each plan\n",
    "        \n",
    "        # 1. Select link randomly from available options\n",
    "        \n",
    "        # 2. If source/dest differ + active \n",
    "        \n",
    "        # a. Loop through each of the links that is for this job\n",
    "        \n",
    "        # b. Loop through each of the active jobs that use this link\n",
    "        \n",
    "        # c. Find the bottleneck thruput based on proportions and reserve\n",
    "        # we will have slight inefficiency due to sequential reserve system but it'll be redundant\n",
    "        # across all users\n",
    "        \n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Users, Servers, Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Make Simulation Parameters\n",
    "\"\"\"\n",
    "sim_param = Sim_Params(time_steps=5, x_length = 5, y_length = 5, max_edge_length=2)\n",
    "boundaries = np.array([[0,sim_param.x_length],[0,sim_param.y_length]])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Make Job Profiles\n",
    "\"\"\"\n",
    "# REsources used are CPU (no. cores) storage (GB), and RAM (GB)\n",
    "# througput is in mb/s\n",
    "# Latency is in ms\n",
    "\n",
    "job_profile1 = Job_Profile(job_name = \"VR\",\n",
    "                           latency_req_range=[25, 40], \n",
    "                           thruput_req_range=[50/1000, 200/1000], \n",
    "                           length_range=[5,5],  \n",
    "                           placement_rsrc_range = np.array([[2,3],[8,16],[2,5]]),\n",
    "                           migration_amt_range = [5, 10],\n",
    "                           latency_penalty_range = [0.05, 0.1]) \n",
    "\n",
    "job_profile2 = Job_Profile(job_name = \"Assistant\",\n",
    "                           latency_req_range=[100, 200],\n",
    "                           thruput_req_range=[5/1000, 20/1000],\n",
    "                           length_range=[1,5],\n",
    "                           placement_rsrc_range = np.array([[1,1],[0.5,1],[0.5,1]]),\n",
    "                           migration_amt_range = [0.5, 1],\n",
    "                           latency_penalty_range = [0.01, 0.05])\n",
    "\n",
    "job_profile3 = Job_Profile(job_name = \"AR\",\n",
    "                           latency_req_range=[50, 80], \n",
    "                           thruput_req_range=[20/1000, 50/1000],\n",
    "                           length_range=[1,5],\n",
    "                           placement_rsrc_range = np.array([[1,2],[2,4],[1,2]]),\n",
    "                           migration_amt_range = [2, 3],\n",
    "                           latency_penalty_range = [0.03, 0.08])\n",
    "\n",
    "job_profiles = [job_profile1, job_profile2, job_profile3]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Make Servers\n",
    "\"\"\"\n",
    "\n",
    "# Server Settings\n",
    "num_server_l1 = 10\n",
    "num_server_l2 = 3\n",
    "num_server_l3 = 1\n",
    "\n",
    "num_resource = 3\n",
    "weak_range = np.array([[4,8],[1000,1500],[4,16]])\n",
    "strong_range = np.array([[50,100],[100000,150000],[300,600]])\n",
    "\n",
    "rsrc_cost = np.array([0.03, 0.01, 0.05])\n",
    "\n",
    "# Generate Server\n",
    "servers_l1 = []\n",
    "servers_l2 = []\n",
    "servers_l3 = []\n",
    "idx_counter = 0\n",
    "\n",
    "for i in range(num_server_l1):\n",
    "    servers_l1.append(Server(boundaries,level=1,rand_locs=True,locs=None))\n",
    "    servers_l1[-1].server_resources(num_resource, weak_range, strong_range)\n",
    "    servers_l1[-1].assign_id(idx_counter)\n",
    "    servers_l1[-1].server_resources_cost(num_resource,rsrc_cost)\n",
    "    idx_counter += 1\n",
    "    \n",
    "for i in range(num_server_l2):\n",
    "    servers_l2.append(Server(boundaries,level=2,rand_locs=True,locs=None))\n",
    "    servers_l2[-1].server_resources(num_resource, weak_range, strong_range)\n",
    "    servers_l2[-1].assign_id(idx_counter)\n",
    "    servers_l2[-1].server_resources_cost(num_resource,rsrc_cost)\n",
    "    idx_counter += 1\n",
    "    \n",
    "for i in range(num_server_l3):\n",
    "    servers_l3.append(Server(boundaries,level=3,rand_locs=False,locs=np.array([200,200])))\n",
    "    servers_l3[-1].server_resources(num_resource, weak_range, strong_range)\n",
    "    servers_l3[-1].assign_id(idx_counter)\n",
    "    servers_l3[-1].server_resources_cost(num_resource,rsrc_cost)\n",
    "    idx_counter += 1\n",
    "    \n",
    "servers = servers_l1 + servers_l2 + servers_l3\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Make Links\n",
    "\"\"\"\n",
    "\n",
    "# Link Settings\n",
    "num_link = [0,1,2]\n",
    "prob_link = [0,1,0]\n",
    "lv_minmax = np.array(([[500,1000],[10000,20000],[30000,50000]]))\n",
    "lv1_transmission = 1\n",
    "link_costs = np.array([0.05, 0.02, 0.01])\n",
    "latency_settings = [10, 1] #[ms per switch, ms per mile]\n",
    "\n",
    "links = Link(servers, num_link, prob_link, lv_minmax, link_costs, latency_settings,lv1_transmission)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Make Users\n",
    "\"\"\"\n",
    "\n",
    "# User Settings\n",
    "num_user_m0 = 1 # Pedestrian\n",
    "num_user_m1 = 0 # Public Transport\n",
    "num_user_m2 = 0 # Vehicle\n",
    "\n",
    "max_speed = 2.5\n",
    "lamdas = [1/0.25,1/0.83,1/1.67] # 3 mph, 10 mph, 20 mph\n",
    "num_path = 10\n",
    "\n",
    "# Generate Server\n",
    "users_m0 = []\n",
    "users_m1 = []\n",
    "users_m2 = []\n",
    "idx_counter = 0\n",
    "\n",
    "for i in range(num_user_m0):\n",
    "    users_m0 += [User(boundaries, sim_param.time_steps, 0, lamdas, max_speed, num_path)]\n",
    "    users_m0[-1].generate_MC(servers)\n",
    "    users_m0[-1].assign_id(idx_counter)\n",
    "    idx_counter += 1\n",
    "    \n",
    "for i in range(num_user_m1):\n",
    "    users_m1 += [User(boundaries, sim_param.time_steps, 1, lamdas, max_speed, 1)]\n",
    "    users_m1[-1].generate_MC(servers)\n",
    "    users_m1[-1].assign_id(idx_counter)\n",
    "    idx_counter += 1\n",
    "\n",
    "for i in range(num_user_m2):\n",
    "    users_m2 += [User(boundaries, sim_param.time_steps, 2, lamdas, max_speed, num_path)]\n",
    "    users_m2[-1].generate_MC(servers)\n",
    "    users_m2[-1].assign_id(idx_counter)\n",
    "    idx_counter += 1\n",
    "\n",
    "users = users_m0 + users_m1 + users_m2\n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    "Make Jobs\n",
    "- \"I'm just going to do it\"\n",
    "\"\"\"\n",
    "\n",
    "# Job settings\n",
    "job_type0 = 1 # VR\n",
    "job_type1 = 0 # Assistant\n",
    "job_type2 = 0 # AR\n",
    "\n",
    "jobs0 = []\n",
    "jobs1 = []\n",
    "jobs2 = []\n",
    "idx_counter = 0\n",
    "\n",
    "total_job_count = job_type0+job_type1+job_type2\n",
    "draw_job_id = np.random.choice(total_job_count, total_job_count, replace=False)\n",
    "\n",
    "for i in range(job_type0):\n",
    "    jobs0 += [Job(job_type = 0,\n",
    "                  user_id = draw_job_id[idx_counter],\n",
    "                  time_steps=sim_param.time_steps,\n",
    "                  job_profiles = job_profiles)]\n",
    "    idx_counter += 1\n",
    "    \n",
    "for i in range(job_type1):\n",
    "    jobs1 += [Job(job_type = 1,\n",
    "                  user_id = draw_job_id[idx_counter],\n",
    "                  time_steps=sim_param.time_steps,\n",
    "                  job_profiles = job_profiles)]\n",
    "    idx_counter += 1\n",
    "    \n",
    "for i in range(job_type2):\n",
    "    jobs2 += [Job(job_type = 2,\n",
    "                  user_id = draw_job_id[idx_counter],\n",
    "                  time_steps=sim_param.time_steps,\n",
    "                  job_profiles=job_profiles)]\n",
    "    idx_counter += 1\n",
    "    \n",
    "jobs = jobs0 + jobs1 + jobs2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make ILP Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-9ce74547857b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msuper_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPlanGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mservers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim_param\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moptim_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptim_PlanGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mservers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim_param\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/MEC_research/solvers/Optim_PlanGenerator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, users, servers, links, jobs, sim_params)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt_feasibility_constraints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt_resource_constraints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt_objective_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \"\"\"\n",
      "\u001b[0;32m~/MEC_research/solvers/Optim_PlanGenerator.py\u001b[0m in \u001b[0;36mopt_objective_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    359\u001b[0m                                     \u001b[0;32mif\u001b[0m \u001b[0ms1\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0ms2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0ms3\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0ms4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m                                         \u001b[0mmig_bw_cost_list\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m                                         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms4\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mservice_bw_cost_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m                                             \u001b[0mservice_bw_cost_list\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m                                         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlatency_list1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "super_prob = PlanGenerator(users, servers, links, jobs, sim_param)\n",
    "optim_prob = Optim_PlanGenerator(users, servers, links, jobs, sim_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_prob.prob.solve()\n",
    "print(\"Status:\", constants.LpStatus[optim_prob.prob.status])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Migration Plan Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ILP_mig_plan = Migration_Plans(users, jobs, sim_param) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ILP_mig_plan.mig_plan_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw Plan From ILP \n",
    "\n",
    "The hardest task is to draw the plan from ILP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_(0,_1,_1,_0,_1,_0) = 1.0\n",
      "h_(0,_1,__1,_1,_2,_0) = 1.0\n",
      "h_(0,__1,_1,__1,_0,_0) = 1.0\n"
     ]
    }
   ],
   "source": [
    "for v in optim_prob.prob.variables():\n",
    "    if v.varValue>0:\n",
    "        print(v.name, \"=\", v.varValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ILP_mig_plan.from_ILP(optim_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'time_slot': array([0., 1.]),\n",
       "  'user_active_flag': array([1., 1.]),\n",
       "  'user_voronoi': array([1., 1.]),\n",
       "  'source_server': array([1., 1.]),\n",
       "  'dest_server': array([1., 1.]),\n",
       "  'mig_rate': array([0., 0.]),\n",
       "  'link_id': array([0., 0.])}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ILP_mig_plan.mig_plan_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(10)\n",
    "a[1:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
