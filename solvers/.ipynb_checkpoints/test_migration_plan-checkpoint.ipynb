{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Migration Plan\n",
    "\n",
    "Test Migration plan class (in classes folder) by:\n",
    "- First make ILP problem identical to last time\n",
    "- Make mig class based on users created\n",
    "- Try to devise a way to take ILP decision values and make plan out of that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Generic Classes\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "# Import All Custom Classes\n",
    "import os, sys\n",
    "sys.path.append(os.path.pardir+\"/classes\")\n",
    "\n",
    "from Server import *\n",
    "from User import *\n",
    "from Link import *\n",
    "from Job import *\n",
    "\n",
    "# Import Solver Classes\n",
    "from Optim_PlanGenerator import *\n",
    "from SeqGreedy_PlanGenerator import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class Migration_Plans:\n",
    "    \"\"\"\n",
    "    Migration_Plans: \n",
    "        - Collects all migration plans generated for an entire system\n",
    "        - mig_plan_dict : 6 x time_steps np array with rows\n",
    "            - timeslot, user_active_flag, usr_voronoi, source_svr, dest_svr, mig_rate\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, users, jobs, sim_params):\n",
    "        \"\"\"\n",
    "        users - list of user class (used to extract user location)\n",
    "        time_steps - how many timesteps to simulate user movement for\n",
    "        \"\"\"\n",
    "        \n",
    "        self.mig_plan_dict = {}\n",
    "        self.sim_params = sim_params\n",
    "        \n",
    "        # Initialize dictionary \n",
    "        self.dict_init(users,jobs,sim_params.time_steps)\n",
    "    \n",
    "    \"\"\"\n",
    "    Init Helper Function\n",
    "    \"\"\"\n",
    "    \n",
    "    def dict_init(self, users, jobs, time_steps):\n",
    "        \n",
    "        param_collection = [\"time_slot\", \"user_active_flag\", \n",
    "                            \"user_voronoi\", \"source_server\", \n",
    "                            \"dest_server\", \"mig_rate\",\n",
    "                            \"mig_link_id\", \"service_link_id\",\n",
    "                            \"service_thruput\", \"latency\"]\n",
    "        \n",
    "        for u in range(len(users)):\n",
    "            temp_usr_dict = {}\n",
    "            \n",
    "            for p in param_collection:\n",
    "                temp_usr_dict[p] = np.zeros(time_steps)\n",
    "            \n",
    "            # Record active time and user voronoi\n",
    "            for t in range(int(time_steps)):\n",
    "                temp_usr_dict[\"time_slot\"][t] = t\n",
    "                temp_usr_dict[\"user_voronoi\"][t] = users[u].user_voronoi_true[t]\n",
    "                temp_usr_dict[\"user_active_flag\"][t] = jobs[u].active_time[t]\n",
    "            \n",
    "            self.mig_plan_dict[u] = temp_usr_dict\n",
    "    \n",
    "    \"\"\"\n",
    "    Extraction Functions\n",
    "    \"\"\"\n",
    "    \n",
    "    def from_ILP(self, ILP_prob, solve_flag = True):\n",
    "        \"\"\"\n",
    "        From decision variables h we want to replace the zero vectors of \n",
    "        self.mig_plan_dict with relevant values based on the decision vars\n",
    "        \n",
    "        Input: ILP_prob - an Optim_PlanGenerator object that already has been optimized\n",
    "        \"\"\"\n",
    "        \n",
    "        if solve_flag:\n",
    "            ILP_prob.prob.solve()\n",
    "        \n",
    "        # 1. Loop through all h_vars and obtain those that have been selected\n",
    "        h_hit_keys = []\n",
    "        \n",
    "        for h_key in ILP_prob.h_vars.keys():\n",
    "            if ILP_prob.h_vars[h_key].varValue>0:\n",
    "                h_hit_keys += [h_key]\n",
    "            \n",
    "        \n",
    "        # 2. Loop through each of the users and isolate variables that pertain to them\n",
    "        for j in range(len(ILP_prob.jobs)):\n",
    "            uh_keys = []\n",
    "            \n",
    "            # Collect all keys from a certain user\n",
    "            for hit_key in h_hit_keys:\n",
    "                if hit_key[0] == j: # If of the correct user\n",
    "                    uh_keys += [hit_key]\n",
    "            \n",
    "            \n",
    "            # Reorder the hit keys in terms of time\n",
    "            uh_keys_ordered = []\n",
    "            curr_time = -1 \n",
    "            for l in range(len(uh_keys)):\n",
    "                time_key = None\n",
    "                for key in uh_keys:\n",
    "                    if key[3] == curr_time:\n",
    "                        break\n",
    "                uh_keys_ordered += [key]\n",
    "                curr_time = key[4]\n",
    "                uh_keys.remove(key)\n",
    "        \n",
    "            self.ILP_plan_extract(uh_keys_ordered,j)\n",
    "        \n",
    "        # 3. Reserve Resources From Resource Constraints\n",
    "        for j in range(len(ILP_prob.jobs)):\n",
    "            placement_rsrc = ILP_prob.jobs[j].placement_rsrc\n",
    "            mig_rsrc = ILP_prob.jobs[j].migration_rsrc\n",
    "            service_bw = ILP_prob.jobs[j].thruput_req\n",
    "            \n",
    "            plan_dict = self.mig_plan_dict[j]\n",
    "            for t in range(self.sim_params.time_steps):\n",
    "                # Reserve Placement Cost & Mig link cost\n",
    "                source_svr = int(plan_dict['source_server'][t])\n",
    "                dest_svr = int(plan_dict['dest_server'][t])\n",
    "                mig_rate = plan_dict['mig_rate'][t]\n",
    "                path_idx = int(plan_dict['mig_link_id'][t])\n",
    "                \n",
    "                if source_svr == dest_svr:\n",
    "                    ILP_prob.resource_constraints.server_rsrc[source_svr,:,t] -= placement_rsrc\n",
    "                else:\n",
    "                    ILP_prob.resource_constraints.server_rsrc[source_svr,:,t] -= placement_rsrc\n",
    "                    ILP_prob.resource_constraints.server_rsrc[dest_svr,:,t] -= placement_rsrc\n",
    "                    \n",
    "                    avail_link = ILP_prob.resource_constraints.link_rsrc[:,:,t]\n",
    "                    mig_links = ILP_prob.links.get_subpath(source_svr,dest_svr,path_idx)\n",
    "                    remain_link = avail_link - (mig_rsrc*mig_rate*mig_links)\n",
    "                    \n",
    "                    ILP_prob.resource_constraints.link_rsrc[:,:,t] = remain_link\n",
    "                \n",
    "                # Reserve Expected Service BAndwidth Cost\n",
    "                avail_link = ILP_prob.resource_constraints.link_rsrc[:,:,t]\n",
    "                exp_service = np.zeros((len(ILP_prob.servers),len(ILP_prob.servers)))\n",
    "                \n",
    "                for s_var in range(len(ILP_prob.servers)):\n",
    "                    if s_var != source_svr:\n",
    "                        avg_link = ILP_prob.links.get_avgpath(source_svr,s_var)\n",
    "                        usr_job_flag = ILP_prob.users[j].server_prob[s_var,t]\n",
    "                        expected_sbw = np.multiply(service_bw, avg_link)\n",
    "                        exp_service += expected_sbw\n",
    "                \n",
    "                remain_link = avail_link - exp_service\n",
    "                ILP_prob.resource_constraints.link_rsrc[:,:,t] = remain_link\n",
    "                \n",
    "        \n",
    "        self.prob = ILP_prob\n",
    "        self.service_path_selection()\n",
    "        self.thruput_selection()\n",
    "        return\n",
    "    \n",
    "    def from_seq_greedy(self,SG_prob):\n",
    "        \"\"\"\n",
    "        From the migration plan problem, do the entire procedure of reserving resources and \n",
    "        generating final migration plan -- how will we do this for batch?\n",
    "        \"\"\"\n",
    "        \n",
    "        # Should add convert node informations\n",
    "\n",
    "        self.prob = SG_prob\n",
    "        \n",
    "        # Loop through time and user to generate incoming plans\n",
    "        for t in range(self.sim_params.time_steps):\n",
    "            for j in range(len(self.prob.jobs)):\n",
    "                \n",
    "                # 1. Check for user arrival time\n",
    "                if t == self.prob.jobs[j].arrival_time:\n",
    "                    \n",
    "                    # 0. Update user server prob\n",
    "                    self.prob.users[j].update_voronoi_probs(time_passed = t)\n",
    "                    \n",
    "                    node_bans = []\n",
    "                    path_bans = []\n",
    "                    approved_flag = False\n",
    "                    \n",
    "                    while_idx = 0\n",
    "                    \n",
    "                    while not approved_flag:\n",
    "                        print(\"usr:\",j,\"reserve:\",while_idx)\n",
    "                        while_idx += 1\n",
    "                    \n",
    "                        # 2. If user arrives, make plan\n",
    "                        self.prob.calc_all_costs(j=0)\n",
    "                        self.prob.obtain_minimum_cost_j(j=0)\n",
    "\n",
    "                        # Start Node and End Node of Mig plan\n",
    "                        start_node = self.prob.convert_st2node[j][(-1,-1)]\n",
    "                        end_node = self.prob.convert_st2node[j][(-1,self.sim_params.time_steps)]\n",
    "\n",
    "                        node_num, link_num = self.prob.dijkstra_j(j=j,start_node=start_node,\n",
    "                                                                     end_node=end_node)\n",
    "                        \n",
    "                        \n",
    "                        # 3. Repeat resource reservation until no conflicts --> or reject job\n",
    "                        node_bans, path_bans, approved_flag = self.prob.check_reserve_resource(j,\n",
    "                                                              node_num,link_num)\n",
    "                        \n",
    "                        # Update cost graph\n",
    "                        if not approved_flag:\n",
    "                            self.prob.update_costs(j, node_bans,path_bans)\n",
    "                    \n",
    "                    \n",
    "                    # Extract plan and record to system\n",
    "                    self.seq_greedy_plan_extract(node_orders=node_num, \n",
    "                                                 link_path_orders=link_num, \n",
    "                                                 job_num=j)\n",
    "\n",
    "        self.service_path_selection()\n",
    "        self.thruput_selection()\n",
    "    \n",
    "    \"\"\"\n",
    "    Extraction function helpers\n",
    "    \"\"\"\n",
    "    \n",
    "    # ILP\n",
    "    \n",
    "    def ILP_plan_extract(self, uh_keys_ordered, job_num):\n",
    "        \"\"\"\n",
    "        Loop through the ordered selected keys for a single user \n",
    "        And generate np arrays that will correspond to plans\n",
    "        Inputs:\n",
    "            uh_keys_ordered: list of tupels that represent h-variables in ILP Solution\n",
    "            job_num: job id \n",
    "        \"\"\"\n",
    "        \n",
    "        active = True\n",
    "        inactive = False\n",
    "        \n",
    "        # Loop through each of the keys (Use switch cases below)\n",
    "        for uh_key in uh_keys_ordered:\n",
    "            start_time, end_time = uh_key[3], uh_key[4]\n",
    "            source_server,dest_server = uh_key[1], uh_key[2]\n",
    "            link_path = uh_key[5]\n",
    "            \n",
    "            case = (source_server >= 0, dest_server >= 0) # server source, dest active/inactive\n",
    "            \n",
    "            if case == (active, active) or case == (inactive,inactive):\n",
    "                self.mig_plan_dict[job_num][\"source_server\"][start_time:end_time] = source_server\n",
    "                self.mig_plan_dict[job_num][\"dest_server\"][start_time:end_time] = dest_server\n",
    "                \n",
    "                # Migration length find\n",
    "                if source_server != dest_server:\n",
    "                    mig_length = end_time - start_time\n",
    "                    self.mig_plan_dict[job_num][\"mig_rate\"][start_time:end_time] = 1/mig_length\n",
    "                    self.mig_plan_dict[job_num][\"mig_link_id\"][start_time:end_time] = link_path\n",
    "                    \n",
    "            elif case == (inactive, active) or case == (active, inactive):\n",
    "                # The entire column in the plan is considered inactive/active\n",
    "                self.mig_plan_dict[job_num][\"source_server\"][start_time:end_time] = source_server\n",
    "                self.mig_plan_dict[job_num][\"dest_server\"][start_time:end_time] = source_server\n",
    "    \n",
    "    # HEuristic\n",
    "    \n",
    "    def seq_greedy_plan_extract(self, node_orders, link_path_orders, job_num):\n",
    "        \"\"\"\n",
    "        Loop through the ordered selected nodes for a single user \n",
    "        And generate np arrays that will correspond to plans\n",
    "        Inputs:\n",
    "            node_orders: Sequence of nodes in mig graph that make up a plan\n",
    "            link_path_orders : which path was taken between two nodes in mig graph\n",
    "            job_num: job id \n",
    "        \"\"\"\n",
    "        \n",
    "        active = True\n",
    "        inactive = False\n",
    "        \n",
    "        # Pull pairs of nodes that are connected together\n",
    "        pair_list = []\n",
    "        path_idx = 0\n",
    "        for i in range(len(node_orders)-1):\n",
    "            pair_list += [(node_orders[i],node_orders[i+1])]\n",
    "        \n",
    "        # Loop through each of the keys (Use switch cases below)\n",
    "        for (node1,node2) in pair_list:\n",
    "            (source_server, start_time) = self.prob.convert_node2st[job_num][node1]\n",
    "            (dest_server, end_time) = self.prob.convert_node2st[job_num][node2]\n",
    "            link_path = link_path_orders[path_idx]\n",
    "            path_idx += 1\n",
    "            \n",
    "            case = (source_server >= 0, dest_server >= 0) # server source, dest active/inactive\n",
    "            \n",
    "            if case == (active, active) or case == (inactive,inactive):\n",
    "                self.mig_plan_dict[job_num][\"source_server\"][start_time:end_time] = source_server\n",
    "                self.mig_plan_dict[job_num][\"dest_server\"][start_time:end_time] = dest_server\n",
    "                \n",
    "                # Migration length find\n",
    "                if source_server != dest_server:\n",
    "                    mig_length = end_time - start_time\n",
    "                    self.mig_plan_dict[job_num][\"mig_rate\"][start_time:end_time] = 1/mig_length\n",
    "                    self.mig_plan_dict[job_num][\"mig_link_id\"][start_time:end_time] = link_path\n",
    "                    \n",
    "            elif case == (inactive, active) or case == (active, inactive):\n",
    "                # The entire column in the plan is considered inactive/active\n",
    "                self.mig_plan_dict[job_num][\"source_server\"][start_time:end_time] = source_server\n",
    "                self.mig_plan_dict[job_num][\"dest_server\"][start_time:end_time] = source_server\n",
    "    \n",
    "        \n",
    "    def service_path_selection(self):\n",
    "        \"\"\"\n",
    "        take into a consideration the resources at each link at each timestep, and determine\n",
    "        Inputs:\n",
    "        links - a link instance of the simulation\n",
    "        jobs - a list of job objects each with their job size \n",
    "        \n",
    "        Updates migration plan to determine throughput of service at each instance\n",
    "        \"\"\"\n",
    "        \n",
    "        switch_latency = self.prob.links.switch_delay\n",
    "        dist_latency = self.prob.links.dist_delay\n",
    "        server_distances = self.prob.links.calc_distance(self.prob.servers)\n",
    "        \n",
    "        # Loop thru plan - pick service and calc latency for each ts\n",
    "        for j,t in itertools.product(range(len(self.prob.jobs)),range(self.sim_params.time_steps)):\n",
    "            usr_svr = int(self.mig_plan_dict[j][\"user_voronoi\"][t])\n",
    "            job_svr = int(self.mig_plan_dict[j][\"source_server\"][t])\n",
    "            \n",
    "            if usr_svr != job_svr:\n",
    "                # Calculate which path\n",
    "                num_path = int(self.prob.links.num_path[job_svr,usr_svr])\n",
    "                select_path = np.random.randint(0,num_path)\n",
    "                self.mig_plan_dict[j]['service_link_id'][t] = select_path\n",
    "            \n",
    "                # Calculate Latency\n",
    "                service_path = self.prob.links.get_subpath(job_svr,usr_svr,select_path)\n",
    "                num_switch = np.sum(np.sum(service_path,axis=1),axis=0)\n",
    "                \n",
    "                latency_dists = np.multiply(service_path,server_distances)\n",
    "                num_dist = np.sum(np.sum(latency_dists,axis=1),axis=0)\n",
    "               \n",
    "                self.mig_plan_dict[j]['latency'][t] = switch_latency * num_switch + num_dist * dist_latency\n",
    "            \n",
    "            else:\n",
    "                self.mig_plan_dict[j][\"service_link_id\"][t] = -1\n",
    "                \n",
    "    def thruput_selection(self):\n",
    "        \"\"\"\n",
    "        After running service_path_selection() we can pick thruput of each job at each timestep\n",
    "        \"\"\"\n",
    "        \n",
    "        # Loop through each timestep \n",
    "        for t in range(self.sim_params.time_steps):\n",
    "            \n",
    "            service_thruput = np.zeros(self.prob.links.distances.shape)\n",
    "            job_thruputs = []\n",
    "            \n",
    "            # Add all \n",
    "            for j in range(len(self.prob.jobs)):\n",
    "                # Add to list job idx and thruput\n",
    "                job_thruputs += [self.prob.jobs[j].thruput_req]\n",
    "            \n",
    "            approved_flag = False\n",
    "            \n",
    "            # Adjust throughputs for this timestep\n",
    "            while not approved_flag:\n",
    "                for j in range(len(self.prob.jobs)):\n",
    "                    if self.mig_plan_dict[j][\"service_link_id\"][t] > -1:\n",
    "                        usr_svr = int(self.mig_plan_dict[j][\"user_voronoi\"][t])\n",
    "                        job_svr = int(self.mig_plan_dict[j][\"source_server\"][t])\n",
    "                        path_id = int(self.mig_plan_dict[j][\"service_link_id\"][t])\n",
    "\n",
    "                        service_links_j = self.prob.links.get_subpath(job_svr,usr_svr,path_id)\n",
    "                        service_thruput += job_thruputs[j] * service_links_j\n",
    "\n",
    "                remainder_link = self.prob.resource_constraints.link_rsrc[:,:,t] - service_thruput\n",
    "                \n",
    "                one_coor = zip(*np.where(remainder_link < 0))\n",
    "\n",
    "                if len(list(one_coor)) == 0:\n",
    "                    approved_flag = True\n",
    "                    continue\n",
    "                    \n",
    "                struck_jobs = []\n",
    "                \n",
    "                for (s1,s2) in one_coor:\n",
    "                    for j in range(len(self.prob.jobs)):\n",
    "                        if self.mig_plan_dict[j][\"service_link_id\"][t] > -1:\n",
    "                            usr_svr = int(self.mig_plan_dict[j][\"user_voronoi\"][t])\n",
    "                            job_svr = int(self.mig_plan_dict[j][\"source_server\"][t])\n",
    "                            path_id = int(self.mig_plan_dict[j][\"service_link_id\"][t])\n",
    "\n",
    "                            service_links_j = self.prob.links.get_subpath(job_svr,usr_svr,path_id)\n",
    "\n",
    "                            if service_links_j[s1,s2] > 0 and (j not in struck_jobs):\n",
    "                                job_thruputs[j] *= 0.9\n",
    "                                struck_jobs += [j]\n",
    "                                \n",
    "            # Record throughput for each job\n",
    "            for j in range(len(self.prob.jobs)):\n",
    "                thru_flag = (self.mig_plan_dict[j][\"service_link_id\"][t] > -1)\n",
    "                self.mig_plan_dict[j][\"service_thruput\"][t] = thru_flag * job_thruputs[j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Users, Servers, Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Make Simulation Parameters\n",
    "\"\"\"\n",
    "sim_param = Sim_Params(time_steps=5, x_length = 5, y_length = 5, max_edge_length=2)\n",
    "boundaries = np.array([[0,sim_param.x_length],[0,sim_param.y_length]])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Make Job Profiles\n",
    "\"\"\"\n",
    "# REsources used are CPU (no. cores) storage (GB), and RAM (GB)\n",
    "# througput is in mb/s\n",
    "# Latency is in ms\n",
    "\n",
    "job_profile1 = Job_Profile(job_name = \"VR\",\n",
    "                           latency_req_range=[0, 0], \n",
    "                           thruput_req_range=[50/1000, 200/1000], \n",
    "                           length_range=[5,5],  \n",
    "                           placement_rsrc_range = np.array([[2,3],[8,16],[2,5]]),\n",
    "                           migration_amt_range = [5, 10],\n",
    "                           latency_penalty_range = [1,11])#[0.05, 0.1]) \n",
    "\n",
    "job_profile2 = Job_Profile(job_name = \"Assistant\",\n",
    "                           latency_req_range=[100, 200],\n",
    "                           thruput_req_range=[5/1000, 20/1000],\n",
    "                           length_range=[1,5],\n",
    "                           placement_rsrc_range = np.array([[1,1],[0.5,1],[0.5,1]]),\n",
    "                           migration_amt_range = [0.5, 1],\n",
    "                           latency_penalty_range = [0.01, 0.05])\n",
    "\n",
    "job_profile3 = Job_Profile(job_name = \"AR\",\n",
    "                           latency_req_range=[50, 80], \n",
    "                           thruput_req_range=[20/1000, 50/1000],\n",
    "                           length_range=[1,5],\n",
    "                           placement_rsrc_range = np.array([[1,2],[2,4],[1,2]]),\n",
    "                           migration_amt_range = [2, 3],\n",
    "                           latency_penalty_range = [0.03, 0.08])\n",
    "\n",
    "job_profiles = [job_profile1, job_profile2, job_profile3]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Make Servers\n",
    "\"\"\"\n",
    "\n",
    "# Server Settings\n",
    "num_server_l1 = 3\n",
    "num_server_l2 = 2\n",
    "num_server_l3 = 1\n",
    "\n",
    "num_resource = 3\n",
    "weak_range = np.array([[4,8],[1000,1500],[4,16]])\n",
    "strong_range = np.array([[50,100],[100000,150000],[300,600]])\n",
    "\n",
    "rsrc_cost = np.array([0.03, 0.01, 0.05])\n",
    "\n",
    "# Generate Server\n",
    "servers_l1 = []\n",
    "servers_l2 = []\n",
    "servers_l3 = []\n",
    "idx_counter = 0\n",
    "\n",
    "for i in range(num_server_l1):\n",
    "    servers_l1.append(Server(boundaries,level=1,rand_locs=True,locs=None))\n",
    "    servers_l1[-1].server_resources(num_resource, weak_range, strong_range)\n",
    "    servers_l1[-1].assign_id(idx_counter)\n",
    "    servers_l1[-1].server_resources_cost(num_resource,rsrc_cost)\n",
    "    idx_counter += 1\n",
    "    \n",
    "for i in range(num_server_l2):\n",
    "    servers_l2.append(Server(boundaries,level=2,rand_locs=True,locs=None))\n",
    "    servers_l2[-1].server_resources(num_resource, weak_range, strong_range)\n",
    "    servers_l2[-1].assign_id(idx_counter)\n",
    "    servers_l2[-1].server_resources_cost(num_resource,rsrc_cost)\n",
    "    idx_counter += 1\n",
    "    \n",
    "for i in range(num_server_l3):\n",
    "    servers_l3.append(Server(boundaries,level=3,rand_locs=False,locs=np.array([200,200])))\n",
    "    servers_l3[-1].server_resources(num_resource, weak_range, strong_range)\n",
    "    servers_l3[-1].assign_id(idx_counter)\n",
    "    servers_l3[-1].server_resources_cost(num_resource,rsrc_cost)\n",
    "    idx_counter += 1\n",
    "    \n",
    "servers = servers_l1 + servers_l2 + servers_l3\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Make Links\n",
    "\"\"\"\n",
    "\n",
    "# Link Settings\n",
    "num_link = [0,1,2]\n",
    "prob_link = [0,1,0]\n",
    "lv_minmax = np.array(([[500,1000],[10000,20000],[30000,50000]]))\n",
    "lv1_transmission = 1\n",
    "link_costs = np.array([0.05, 0.02, 0.01])\n",
    "latency_settings = [1000, 100] #[ms per switch, ms per mile]\n",
    "\n",
    "links = Link(servers, num_link, prob_link, lv_minmax, link_costs, latency_settings,lv1_transmission)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Make Users\n",
    "\"\"\"\n",
    "\n",
    "# User Settings\n",
    "num_user_m0 = 0 # Pedestrian\n",
    "num_user_m1 = 0 # Public Transport\n",
    "num_user_m2 = 1 # Vehicle\n",
    "\n",
    "max_speed = 2.5\n",
    "lamdas = [1/0.25,1/0.83,1/1.67] # 3 mph, 10 mph, 20 mph\n",
    "num_path = 10\n",
    "\n",
    "# Generate Server\n",
    "users_m0 = []\n",
    "users_m1 = []\n",
    "users_m2 = []\n",
    "idx_counter = 0\n",
    "\n",
    "for i in range(num_user_m0):\n",
    "    users_m0 += [User(boundaries, sim_param.time_steps, 0, lamdas, max_speed, num_path)]\n",
    "    users_m0[-1].generate_MC(servers)\n",
    "    users_m0[-1].assign_id(idx_counter)\n",
    "    idx_counter += 1\n",
    "    \n",
    "for i in range(num_user_m1):\n",
    "    users_m1 += [User(boundaries, sim_param.time_steps, 1, lamdas, max_speed, 1)]\n",
    "    users_m1[-1].generate_MC(servers)\n",
    "    users_m1[-1].assign_id(idx_counter)\n",
    "    idx_counter += 1\n",
    "\n",
    "for i in range(num_user_m2):\n",
    "    users_m2 += [User(boundaries, sim_param.time_steps, 2, lamdas, max_speed, num_path)]\n",
    "    users_m2[-1].generate_MC(servers)\n",
    "    users_m2[-1].assign_id(idx_counter)\n",
    "    idx_counter += 1\n",
    "\n",
    "users = users_m0 + users_m1 + users_m2\n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    "Make Jobs\n",
    "- \"I'm just going to do it\"\n",
    "\"\"\"\n",
    "\n",
    "# Job settings\n",
    "job_type0 = 1 # VR\n",
    "job_type1 = 0 # Assistant\n",
    "job_type2 = 0 # AR\n",
    "\n",
    "jobs0 = []\n",
    "jobs1 = []\n",
    "jobs2 = []\n",
    "idx_counter = 0\n",
    "\n",
    "total_job_count = job_type0+job_type1+job_type2\n",
    "draw_job_id = np.random.choice(total_job_count, total_job_count, replace=False)\n",
    "\n",
    "for i in range(job_type0):\n",
    "    jobs0 += [Job(job_type = 0,\n",
    "                  user_id = draw_job_id[idx_counter],\n",
    "                  time_steps=sim_param.time_steps,\n",
    "                  job_profiles = job_profiles)]\n",
    "    idx_counter += 1\n",
    "    \n",
    "for i in range(job_type1):\n",
    "    jobs1 += [Job(job_type = 1,\n",
    "                  user_id = draw_job_id[idx_counter],\n",
    "                  time_steps=sim_param.time_steps,\n",
    "                  job_profiles = job_profiles)]\n",
    "    idx_counter += 1\n",
    "    \n",
    "for i in range(job_type2):\n",
    "    jobs2 += [Job(job_type = 2,\n",
    "                  user_id = draw_job_id[idx_counter],\n",
    "                  time_steps=sim_param.time_steps,\n",
    "                  job_profiles=job_profiles)]\n",
    "    idx_counter += 1\n",
    "    \n",
    "jobs = jobs0 + jobs1 + jobs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. ],\n",
       "       [1. , 0.9, 0.6, 0.4, 0.6],\n",
       "       [0. , 0.1, 0.4, 0.6, 0.4],\n",
       "       [0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. ]])"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users[0].server_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make ILP Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_prob = PlanGenerator(users, servers, links, jobs, sim_param)\n",
    "optim_prob = Optim_PlanGenerator(users, servers, links, jobs, sim_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: Not Solved\n"
     ]
    }
   ],
   "source": [
    "#optim_prob.prob.solve()\n",
    "print(\"Status:\", constants.LpStatus[optim_prob.prob.status])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Migration Plan Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "ILP_mig_plan = Migration_Plans(users, jobs, sim_param) \n",
    "ILP_mig_plan.from_ILP(optim_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'time_slot': array([0., 1., 2., 3., 4.]),\n",
       "  'user_active_flag': array([1., 1., 1., 1., 1.]),\n",
       "  'user_voronoi': array([2., 2., 3., 3., 3.]),\n",
       "  'source_server': array([2., 2., 4., 3., 4.]),\n",
       "  'dest_server': array([2., 4., 3., 4., 4.]),\n",
       "  'mig_rate': array([0., 1., 1., 1., 0.]),\n",
       "  'mig_link_id': array([0., 0., 1., 0., 0.]),\n",
       "  'service_link_id': array([-1., -1.,  0., -1.,  1.]),\n",
       "  'service_thruput': array([0.        , 0.        , 0.06312773, 0.        , 0.06312773]),\n",
       "  'latency': array([    0.        ,     0.        ,  1152.65692936,     0.        ,\n",
       "         57898.40162042])}}"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ILP_mig_plan.mig_plan_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0631277272808401"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs[0].thruput_req"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw Plan From Seq Greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usr: 0 reserve: 0\n"
     ]
    }
   ],
   "source": [
    "SG_prob = SeqGreedy_PlanGenerator(users, servers, links, jobs, sim_param)\n",
    "SG_plan = Migration_Plans(users,jobs,sim_param)\n",
    "SG_plan.from_seq_greedy(SG_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time_slot': array([0., 1., 2., 3., 4.]),\n",
       " 'user_active_flag': array([1., 1., 1., 1., 1.]),\n",
       " 'user_voronoi': array([2., 2., 3., 3., 3.]),\n",
       " 'source_server': array([2., 2., 4., 3., 4.]),\n",
       " 'dest_server': array([2., 4., 3., 4., 4.]),\n",
       " 'mig_rate': array([0., 1., 1., 1., 0.]),\n",
       " 'mig_link_id': array([0., 1., 0., 0., 0.]),\n",
       " 'service_link_id': array([-1., -1.,  0., -1.,  0.]),\n",
       " 'service_thruput': array([0.        , 0.        , 0.06312773, 0.        , 0.06312773]),\n",
       " 'latency': array([   0.        ,    0.        , 1152.65692936,    0.        ,\n",
       "        1152.65692936])}"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SG_plan.mig_plan_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.           2.52857867   4.09080047   1.52978438   2.98480697\n",
      "  281.63667495]\n",
      " [  2.52857867   0.           2.0726251    1.49596706   1.07830125\n",
      "  279.75732197]\n",
      " [  4.09080047   2.0726251    0.           2.58736949   1.1321021\n",
      "  277.73509152]\n",
      " [  1.52978438   1.49596706   2.58736949   0.           1.52656929\n",
      "  280.12551313]\n",
      " [  2.98480697   1.07830125   1.1321021    1.52656929   0.\n",
      "  278.85850308]\n",
      " [281.63667495 279.75732197 277.73509152 280.12551313 278.85850308\n",
      "    0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(links.distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 * False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
