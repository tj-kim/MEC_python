{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Migration Plan\n",
    "\n",
    "Test Migration plan class (in classes folder) by:\n",
    "- First make ILP problem identical to last time\n",
    "- Make mig class based on users created\n",
    "- Try to devise a way to take ILP decision values and make plan out of that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Generic Classes\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "# Import All Custom Classes\n",
    "import os, sys\n",
    "sys.path.append(os.path.pardir+\"/classes\")\n",
    "\n",
    "from Server import *\n",
    "from User import *\n",
    "from Link import *\n",
    "from Job import *\n",
    "\n",
    "# Import Solver Classes\n",
    "from Optim_PlanGenerator import *\n",
    "from SeqGreedy_PlanGenerator import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class Migration_Plans:\n",
    "    \"\"\"\n",
    "    Migration_Plans: \n",
    "        - Collects all migration plans generated for an entire system\n",
    "        - mig_plan_dict : 6 x time_steps np array with rows\n",
    "            - timeslot, user_active_flag, usr_voronoi, source_svr, dest_svr, mig_rate\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, users, jobs, sim_params):\n",
    "        \"\"\"\n",
    "        users - list of user class (used to extract user location)\n",
    "        time_steps - how many timesteps to simulate user movement for\n",
    "        \"\"\"\n",
    "        \n",
    "        self.mig_plan_dict = {}\n",
    "        self.sim_params = sim_params\n",
    "        \n",
    "        # Initialize dictionary \n",
    "        self.dict_init(users,jobs,sim_params.time_steps)\n",
    "    \n",
    "    \"\"\"\n",
    "    Init Helper Function\n",
    "    \"\"\"\n",
    "    \n",
    "    def dict_init(self, users, jobs, time_steps):\n",
    "        \n",
    "        param_collection = [\"time_slot\", \"user_active_flag\", \n",
    "                            \"user_voronoi\", \"source_server\", \n",
    "                            \"dest_server\", \"mig_rate\",\n",
    "                            \"mig_link_id\", \"service_link_id\",\n",
    "                            \"service_thruput\", \"latency\"]\n",
    "        \n",
    "        for u in range(len(users)):\n",
    "            temp_usr_dict = {}\n",
    "            \n",
    "            for p in param_collection:\n",
    "                temp_usr_dict[p] = np.zeros(time_steps)\n",
    "            \n",
    "            # Record active time and user voronoi\n",
    "            for t in range(int(time_steps)):\n",
    "                temp_usr_dict[\"time_slot\"][t] = t\n",
    "                temp_usr_dict[\"user_voronoi\"][t] = users[u].user_voronoi_true[t]\n",
    "                temp_usr_dict[\"user_active_flag\"][t] = jobs[u].active_time[t]\n",
    "            \n",
    "            self.mig_plan_dict[u] = temp_usr_dict\n",
    "    \n",
    "    \"\"\"\n",
    "    Extraction Functions\n",
    "    \"\"\"\n",
    "    \n",
    "    def from_ILP(self, ILP_prob):\n",
    "        \"\"\"\n",
    "        From decision variables h we want to replace the zero vectors of \n",
    "        self.mig_plan_dict with relevant values based on the decision vars\n",
    "        \n",
    "        Input: ILP_prob - an Optim_PlanGenerator object that already has been optimized\n",
    "        \"\"\"\n",
    "        \n",
    "        # 1. Loop through all h_vars and obtain those that have been selected\n",
    "        h_hit_keys = []\n",
    "        \n",
    "        for h_key in ILP_prob.h_vars.keys():\n",
    "            if ILP_prob.h_vars[h_key].varValue>0:\n",
    "                h_hit_keys += [h_key]\n",
    "            \n",
    "        \n",
    "        # 2. Loop through each of the users and isolate variables that pertain to them\n",
    "        for j in range(len(ILP_prob.jobs)):\n",
    "            uh_keys = []\n",
    "            \n",
    "            # Collect all keys from a certain user\n",
    "            for hit_key in h_hit_keys:\n",
    "                if hit_key[0] == j: # If of the correct user\n",
    "                    uh_keys += [hit_key]\n",
    "            \n",
    "            \n",
    "            # Reorder the hit keys in terms of time\n",
    "            uh_keys_ordered = []\n",
    "            curr_time = -1 \n",
    "            for l in range(len(uh_keys)):\n",
    "                time_key = None\n",
    "                for key in uh_keys:\n",
    "                    if key[3] == curr_time:\n",
    "                        break\n",
    "                uh_keys_ordered += [key]\n",
    "                curr_time = key[4]\n",
    "                uh_keys.remove(key)\n",
    "        \n",
    "            self.ILP_plan_extract(uh_keys_ordered,j)\n",
    "                    \n",
    "        \n",
    "        return\n",
    "    \n",
    "    def from_seq_greedy(self,SG_prob):\n",
    "        \"\"\"\n",
    "        From the migration plan problem, do the entire procedure of reserving resources and \n",
    "        generating final migration plan -- how will we do this for batch?\n",
    "        \"\"\"\n",
    "        \n",
    "        # Should add convert node informations\n",
    "\n",
    "        self.SG_prob = SG_prob\n",
    "        \n",
    "        # Loop through time and user to generate incoming plans\n",
    "        for t in range(self.sim_params.time_steps):\n",
    "            for j in range(len(self.jobs)):\n",
    "                            \n",
    "                # 0. Update user server prob\n",
    "                self.users[j].update_voronoi_probs(time_passed = t)\n",
    "                \n",
    "                # 1. Check for user arrival time\n",
    "                if t == self.users[j].arrival_time:\n",
    "                    \n",
    "                    node_bans = []\n",
    "                    path_bans = []\n",
    "                    approved_flag = False\n",
    "                    \n",
    "                    while_idx = 0\n",
    "                    \n",
    "                    while not approved_flag:\n",
    "                        print(\"usr:\",j,\"reserve:\",while_idx)\n",
    "                        while_idx += 1\n",
    "                    \n",
    "                        # 2. If user arrives, make plan\n",
    "                        SG_prob.calc_all_costs(j=0)\n",
    "                        SG_prob.obtain_minimum_cost_j(j=0)\n",
    "\n",
    "                        # Start Node and End Node of Mig plan\n",
    "                        start_node = self.convert_st2node[(-1,-1)]\n",
    "                        end_node = self.convert_st2node[(-1,self.sim_params.time_steps)]\n",
    "\n",
    "                        node_num, link_num = self.SG_prob.dijkstra_j(j=j,start_node=start_node,\n",
    "                                                                     end_node=end_node)\n",
    "                        \n",
    "                        \n",
    "                        # 3. Repeat resource reservation until no conflicts --> or reject job\n",
    "                        node_bans, path_bans, approved_flag = self.SG_prob.check_reserve_resource(j,\n",
    "                                                              node_num,link_num)\n",
    "                        \n",
    "                        # Update cost graph\n",
    "                        if not approved_flag:\n",
    "                            self.SG_prob.update_costs(j, node_bans,path_bans)\n",
    "                    \n",
    "                    \n",
    "                    # Extract plan and record to system\n",
    "                    self.seq_greedy_plan_extract(node_orders=node_num, \n",
    "                                                 link_path_orders=link_num, \n",
    "                                                 job_num=j)\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    Extraction function helpers\n",
    "    \"\"\"\n",
    "    \n",
    "    # ILP\n",
    "    \n",
    "    def ILP_plan_extract(self, uh_keys_ordered, job_num):\n",
    "        \"\"\"\n",
    "        Loop through the ordered selected keys for a single user \n",
    "        And generate np arrays that will correspond to plans\n",
    "        Inputs:\n",
    "            uh_keys_ordered: list of tupels that represent h-variables in ILP Solution\n",
    "            job_num: job id \n",
    "        \"\"\"\n",
    "        \n",
    "        active = True\n",
    "        inactive = False\n",
    "        \n",
    "        # Loop through each of the keys (Use switch cases below)\n",
    "        for uh_key in uh_keys_ordered:\n",
    "            start_time, end_time = uh_key[3], uh_key[4]\n",
    "            source_server,dest_server = uh_key[1], uh_key[2]\n",
    "            link_path = uh_key[5]\n",
    "            \n",
    "            case = (source_server >= 0, dest_server >= 0) # server source, dest active/inactive\n",
    "            \n",
    "            if case == (active, active) or case == (inactive,inactive):\n",
    "                self.mig_plan_dict[job_num][\"source_server\"][start_time:end_time] = source_server\n",
    "                self.mig_plan_dict[job_num][\"dest_server\"][start_time:end_time] = dest_server\n",
    "                \n",
    "                # Migration length find\n",
    "                if source_server != dest_server:\n",
    "                    mig_length = end_time - start_time\n",
    "                    self.mig_plan_dict[job_num][\"mig_rate\"][start_time:end_time] = 1/mig_length\n",
    "                    self.mig_plan_dict[job_num][\"mig_link_id\"][start_time:end_time] = link_path\n",
    "                    \n",
    "            elif case == (inactive, active) or case == (active, inactive):\n",
    "                # The entire column in the plan is considered inactive/active\n",
    "                self.mig_plan_dict[job_num][\"source_server\"][start_time:end_time] = source_server\n",
    "                self.mig_plan_dict[job_num][\"dest_server\"][start_time:end_time] = source_server\n",
    "    \n",
    "    # HEuristic\n",
    "    \n",
    "    def seq_greedy_plan_extract(self, node_orders, link_path_orders, job_num):\n",
    "        \"\"\"\n",
    "        Loop through the ordered selected nodes for a single user \n",
    "        And generate np arrays that will correspond to plans\n",
    "        Inputs:\n",
    "            node_orders: Sequence of nodes in mig graph that make up a plan\n",
    "            link_path_orders : which path was taken between two nodes in mig graph\n",
    "            job_num: job id \n",
    "        \"\"\"\n",
    "        \n",
    "        active = True\n",
    "        inactive = False\n",
    "        \n",
    "        # Pull pairs of nodes that are connected together\n",
    "        pair_list = []\n",
    "        path_idx = 0\n",
    "        for i in range(len(node_orders)-1):\n",
    "            pair_list += [(node_orders[i],node_orders[i+1])]\n",
    "        \n",
    "        # Loop through each of the keys (Use switch cases below)\n",
    "        for (node1,node2) in pair_list:\n",
    "            (source_server, start_time) = self.SG_prob.convert_node2st[job_num][node1]\n",
    "            (dest_server, end_time) = self.SG_prob.convert_node2st[job_num][node2]\n",
    "            link_path = link_path_orders[path_idx]\n",
    "            path_idx += 1\n",
    "            \n",
    "            case = (source_server >= 0, dest_server >= 0) # server source, dest active/inactive\n",
    "            \n",
    "            if case == (active, active) or case == (inactive,inactive):\n",
    "                self.mig_plan_dict[job_num][\"source_server\"][start_time:end_time] = source_server\n",
    "                self.mig_plan_dict[job_num][\"dest_server\"][start_time:end_time] = dest_server\n",
    "                \n",
    "                # Migration length find\n",
    "                if source_server != dest_server:\n",
    "                    mig_length = end_time - start_time\n",
    "                    self.mig_plan_dict[job_num][\"mig_rate\"][start_time:end_time] = 1/mig_length\n",
    "                    self.mig_plan_dict[job_num][\"mig_link_id\"][start_time:end_time] = link_path\n",
    "                    \n",
    "            elif case == (inactive, active) or case == (active, inactive):\n",
    "                # The entire column in the plan is considered inactive/active\n",
    "                self.mig_plan_dict[job_num][\"source_server\"][start_time:end_time] = source_server\n",
    "                self.mig_plan_dict[job_num][\"dest_server\"][start_time:end_time] = source_server\n",
    "    \n",
    "    # General\n",
    "        \n",
    "    def reserve_service_bw(self,links,jobs):\n",
    "        \"\"\"\n",
    "        take into a consideration the resources at each link at each timestep, and determine\n",
    "        Inputs:\n",
    "        links - a link instance of the simulation\n",
    "        jobs - a list of job objects each with their job size \n",
    "        \n",
    "        Updates migration plan to determine throughput of service at each instance\n",
    "        \"\"\"\n",
    "        \n",
    "        # Loop through each ts\n",
    "        \n",
    "        # Loop through each plan\n",
    "        \n",
    "        # 1. Select link randomly from available options\n",
    "        \n",
    "        # 2. If source/dest differ + active \n",
    "        \n",
    "        # a. Loop through each of the links that is for this job\n",
    "        \n",
    "        # b. Loop through each of the active jobs that use this link\n",
    "        \n",
    "        # c. Find the bottleneck thruput based on proportions and reserve\n",
    "        # we will have slight inefficiency due to sequential reserve system but it'll be redundant\n",
    "        # across all users\n",
    "        \n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Users, Servers, Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Make Simulation Parameters\n",
    "\"\"\"\n",
    "sim_param = Sim_Params(time_steps=5, x_length = 5, y_length = 5, max_edge_length=2)\n",
    "boundaries = np.array([[0,sim_param.x_length],[0,sim_param.y_length]])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Make Job Profiles\n",
    "\"\"\"\n",
    "# REsources used are CPU (no. cores) storage (GB), and RAM (GB)\n",
    "# througput is in mb/s\n",
    "# Latency is in ms\n",
    "\n",
    "job_profile1 = Job_Profile(job_name = \"VR\",\n",
    "                           latency_req_range=[0, 0], \n",
    "                           thruput_req_range=[50/1000, 200/1000], \n",
    "                           length_range=[5,5],  \n",
    "                           placement_rsrc_range = np.array([[2,3],[8,16],[2,5]]),\n",
    "                           migration_amt_range = [5, 10],\n",
    "                           latency_penalty_range = [1,11])#[0.05, 0.1]) \n",
    "\n",
    "job_profile2 = Job_Profile(job_name = \"Assistant\",\n",
    "                           latency_req_range=[100, 200],\n",
    "                           thruput_req_range=[5/1000, 20/1000],\n",
    "                           length_range=[1,5],\n",
    "                           placement_rsrc_range = np.array([[1,1],[0.5,1],[0.5,1]]),\n",
    "                           migration_amt_range = [0.5, 1],\n",
    "                           latency_penalty_range = [0.01, 0.05])\n",
    "\n",
    "job_profile3 = Job_Profile(job_name = \"AR\",\n",
    "                           latency_req_range=[50, 80], \n",
    "                           thruput_req_range=[20/1000, 50/1000],\n",
    "                           length_range=[1,5],\n",
    "                           placement_rsrc_range = np.array([[1,2],[2,4],[1,2]]),\n",
    "                           migration_amt_range = [2, 3],\n",
    "                           latency_penalty_range = [0.03, 0.08])\n",
    "\n",
    "job_profiles = [job_profile1, job_profile2, job_profile3]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Make Servers\n",
    "\"\"\"\n",
    "\n",
    "# Server Settings\n",
    "num_server_l1 = 3\n",
    "num_server_l2 = 2\n",
    "num_server_l3 = 1\n",
    "\n",
    "num_resource = 3\n",
    "weak_range = np.array([[4,8],[1000,1500],[4,16]])\n",
    "strong_range = np.array([[50,100],[100000,150000],[300,600]])\n",
    "\n",
    "rsrc_cost = np.array([0.03, 0.01, 0.05])\n",
    "\n",
    "# Generate Server\n",
    "servers_l1 = []\n",
    "servers_l2 = []\n",
    "servers_l3 = []\n",
    "idx_counter = 0\n",
    "\n",
    "for i in range(num_server_l1):\n",
    "    servers_l1.append(Server(boundaries,level=1,rand_locs=True,locs=None))\n",
    "    servers_l1[-1].server_resources(num_resource, weak_range, strong_range)\n",
    "    servers_l1[-1].assign_id(idx_counter)\n",
    "    servers_l1[-1].server_resources_cost(num_resource,rsrc_cost)\n",
    "    idx_counter += 1\n",
    "    \n",
    "for i in range(num_server_l2):\n",
    "    servers_l2.append(Server(boundaries,level=2,rand_locs=True,locs=None))\n",
    "    servers_l2[-1].server_resources(num_resource, weak_range, strong_range)\n",
    "    servers_l2[-1].assign_id(idx_counter)\n",
    "    servers_l2[-1].server_resources_cost(num_resource,rsrc_cost)\n",
    "    idx_counter += 1\n",
    "    \n",
    "for i in range(num_server_l3):\n",
    "    servers_l3.append(Server(boundaries,level=3,rand_locs=False,locs=np.array([200,200])))\n",
    "    servers_l3[-1].server_resources(num_resource, weak_range, strong_range)\n",
    "    servers_l3[-1].assign_id(idx_counter)\n",
    "    servers_l3[-1].server_resources_cost(num_resource,rsrc_cost)\n",
    "    idx_counter += 1\n",
    "    \n",
    "servers = servers_l1 + servers_l2 + servers_l3\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Make Links\n",
    "\"\"\"\n",
    "\n",
    "# Link Settings\n",
    "num_link = [0,1,2]\n",
    "prob_link = [0,1,0]\n",
    "lv_minmax = np.array(([[500,1000],[10000,20000],[30000,50000]]))\n",
    "lv1_transmission = 1\n",
    "link_costs = np.array([0.05, 0.02, 0.01])\n",
    "latency_settings = [1000, 100] #[ms per switch, ms per mile]\n",
    "\n",
    "links = Link(servers, num_link, prob_link, lv_minmax, link_costs, latency_settings,lv1_transmission)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Make Users\n",
    "\"\"\"\n",
    "\n",
    "# User Settings\n",
    "num_user_m0 = 0 # Pedestrian\n",
    "num_user_m1 = 1 # Public Transport\n",
    "num_user_m2 = 0 # Vehicle\n",
    "\n",
    "max_speed = 2.5\n",
    "lamdas = [1/0.25,1/0.83,1/1.67] # 3 mph, 10 mph, 20 mph\n",
    "num_path = 10\n",
    "\n",
    "# Generate Server\n",
    "users_m0 = []\n",
    "users_m1 = []\n",
    "users_m2 = []\n",
    "idx_counter = 0\n",
    "\n",
    "for i in range(num_user_m0):\n",
    "    users_m0 += [User(boundaries, sim_param.time_steps, 0, lamdas, max_speed, num_path)]\n",
    "    users_m0[-1].generate_MC(servers)\n",
    "    users_m0[-1].assign_id(idx_counter)\n",
    "    idx_counter += 1\n",
    "    \n",
    "for i in range(num_user_m1):\n",
    "    users_m1 += [User(boundaries, sim_param.time_steps, 1, lamdas, max_speed, 1)]\n",
    "    users_m1[-1].generate_MC(servers)\n",
    "    users_m1[-1].assign_id(idx_counter)\n",
    "    idx_counter += 1\n",
    "\n",
    "for i in range(num_user_m2):\n",
    "    users_m2 += [User(boundaries, sim_param.time_steps, 2, lamdas, max_speed, num_path)]\n",
    "    users_m2[-1].generate_MC(servers)\n",
    "    users_m2[-1].assign_id(idx_counter)\n",
    "    idx_counter += 1\n",
    "\n",
    "users = users_m0 + users_m1 + users_m2\n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    "Make Jobs\n",
    "- \"I'm just going to do it\"\n",
    "\"\"\"\n",
    "\n",
    "# Job settings\n",
    "job_type0 = 1 # VR\n",
    "job_type1 = 0 # Assistant\n",
    "job_type2 = 0 # AR\n",
    "\n",
    "jobs0 = []\n",
    "jobs1 = []\n",
    "jobs2 = []\n",
    "idx_counter = 0\n",
    "\n",
    "total_job_count = job_type0+job_type1+job_type2\n",
    "draw_job_id = np.random.choice(total_job_count, total_job_count, replace=False)\n",
    "\n",
    "for i in range(job_type0):\n",
    "    jobs0 += [Job(job_type = 0,\n",
    "                  user_id = draw_job_id[idx_counter],\n",
    "                  time_steps=sim_param.time_steps,\n",
    "                  job_profiles = job_profiles)]\n",
    "    idx_counter += 1\n",
    "    \n",
    "for i in range(job_type1):\n",
    "    jobs1 += [Job(job_type = 1,\n",
    "                  user_id = draw_job_id[idx_counter],\n",
    "                  time_steps=sim_param.time_steps,\n",
    "                  job_profiles = job_profiles)]\n",
    "    idx_counter += 1\n",
    "    \n",
    "for i in range(job_type2):\n",
    "    jobs2 += [Job(job_type = 2,\n",
    "                  user_id = draw_job_id[idx_counter],\n",
    "                  time_steps=sim_param.time_steps,\n",
    "                  job_profiles=job_profiles)]\n",
    "    idx_counter += 1\n",
    "    \n",
    "jobs = jobs0 + jobs1 + jobs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 1.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 1., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users[0].server_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make ILP Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_prob = PlanGenerator(users, servers, links, jobs, sim_param)\n",
    "optim_prob = Optim_PlanGenerator(users, servers, links, jobs, sim_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: Optimal\n"
     ]
    }
   ],
   "source": [
    "optim_prob.prob.solve()\n",
    "print(\"Status:\", constants.LpStatus[optim_prob.prob.status])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Migration Plan Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ILP_mig_plan = Migration_Plans(users, jobs, sim_param) \n",
    "ILP_mig_plan.from_ILP(optim_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'time_slot': array([0., 1., 2., 3., 4.]),\n",
       "  'user_active_flag': array([1., 1., 1., 1., 1.]),\n",
       "  'user_voronoi': array([0., 4., 4., 2., 2.]),\n",
       "  'source_server': array([0., 4., 4., 2., 2.]),\n",
       "  'dest_server': array([4., 4., 2., 2., 2.]),\n",
       "  'mig_rate': array([1., 0., 1., 0., 0.]),\n",
       "  'mig_link_id': array([0., 0., 1., 0., 0.]),\n",
       "  'service_link_id': array([0., 0., 0., 0., 0.]),\n",
       "  'service_thruput': array([0., 0., 0., 0., 0.]),\n",
       "  'latency': array([0., 0., 0., 0., 0.])}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ILP_mig_plan.mig_plan_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_(0,_0,_4,_0,_1,_0) = 1.0\n",
      "h_(0,_2,_2,_3,_4,_0) = 1.0\n",
      "h_(0,_2,__1,_4,_5,_0) = 1.0\n",
      "h_(0,_4,_2,_2,_3,_1) = 1.0\n",
      "h_(0,_4,_4,_1,_2,_0) = 1.0\n",
      "h_(0,__1,_0,__1,_0,_0) = 1.0\n"
     ]
    }
   ],
   "source": [
    "for v in optim_prob.prob.variables():\n",
    "    if v.varValue>0:\n",
    "        print(v.name, \"=\", v.varValue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw Plan From Seq Greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SG_prob = SeqGreedy_PlanGenerator(users, servers, links, jobs, sim_param)\n",
    "SG_prob.calc_all_costs(j=0)\n",
    "SG_prob.obtain_minimum_cost_j(j=0)\n",
    "\n",
    "# Start Node and End Node of Mig plan\n",
    "start_node = SG_prob.convert_st2node[0][(-1,-1)]\n",
    "end_node = SG_prob.convert_st2node[0][(-1,SG_prob.sim_params.time_steps)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_num, link_num = SG_prob.dijkstra_j(j=0, start_node = start_node, end_node = end_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 13, 20, 25, 32, 36]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "SG_mig_plan = Migration_Plans(users, jobs, sim_param)\n",
    "SG_mig_plan.SG_prob = SG_prob\n",
    "SG_mig_plan.seq_greedy_plan_extract(node_orders=node_num, link_path_orders=link_num, job_num=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.94153083e+00, 1.14067042e+03, 6.56762028e+00],\n",
       "       [5.03675820e+00, 1.01503772e+03, 1.36960528e+01],\n",
       "       [6.44770432e+00, 1.33675193e+03, 1.39087579e+01],\n",
       "       [6.67380103e+01, 1.20114954e+05, 4.03088525e+02],\n",
       "       [8.85468431e+01, 1.04055924e+05, 5.05298907e+02],\n",
       "       [1.00000000e+09, 1.00000000e+09, 1.00000000e+09]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SG_prob.resource_constraints.server_rsrc[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_bans, path_bans, approved_flag = SG_prob.check_reserve_resource(j=0,\n",
    "                                                                     shortest_path=node_num,\n",
    "                                                                     shortest_path_link_idx = link_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.18894941e+00, 1.12699603e+03, 2.65348770e+00],\n",
       "       [5.03675820e+00, 1.01503772e+03, 1.36960528e+01],\n",
       "       [6.44770432e+00, 1.33675193e+03, 1.39087579e+01],\n",
       "       [6.67380103e+01, 1.20114954e+05, 4.03088525e+02],\n",
       "       [8.57942617e+01, 1.04042250e+05, 5.01384775e+02],\n",
       "       [1.00000000e+09, 1.00000000e+09, 1.00000000e+09]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SG_prob.resource_constraints.server_rsrc[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_bans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "approved_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
